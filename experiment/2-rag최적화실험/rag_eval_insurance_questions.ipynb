{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install langchain_core\n",
    "!pip install langchain_huggingface\n",
    "!pip install kiwipiepy\n",
    "!pip install konlpy\n",
    "!pip install rank-bm25\n",
    "!pip install chromadb\n",
    "!pip install python-dotenv\n",
    "!pip install pypdf\n",
    "!pip install pymupdf"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "# 1. colab에서 실행할 경우)\n",
    "\n",
    "## 구글 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "base_path = '/content/drive/MyDrive/Projects'\n",
    "\n",
    "## 문서경로\n",
    "doc_path = f'{base_path}/rag최적화실험/documents/상해보험약관.pdf'\n",
    "## 질문+평가 json\n",
    "eval_json_path = f'{base_path}/rag최적화실험/eval_data/상해보험약관_eval.json'\n",
    "env = f'{base_path}/comm/.env'"
   ],
   "id": "f07cd29774f15b44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "# 2. local에서 실행할 경우\n",
    "\n",
    "base_path = './'\n",
    "\n",
    "## 문서경로\n",
    "doc_path = f'{base_path}/documents/상해보험약관.pdf'\n",
    "## 질문+평가 json\n",
    "eval_json_path = f'{base_path}/eval_data/상해보험약관_eval.json'\n",
    "env = f'{base_path}/../../comm/.env'\n",
    "'''"
   ],
   "id": "51eadbc36bfbb715"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# env 설정\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(env)"
   ],
   "id": "720098287cfd7920"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 문서 로드\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(doc_path)\n",
    "docs = loader.load()"
   ],
   "id": "b597bf2ad1a596d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# eval json 로드\n",
    "import json\n",
    "with open(eval_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "  eval_data = json.load(f)"
   ],
   "id": "29b73c13eab54c3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 토크나이저\n",
    "from kiwipiepy import Kiwi\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_tokenize(text):\n",
    "  return \" \".join([token.form for token in kiwi.tokenize(text)])"
   ],
   "id": "cbefb8826c9aaab9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 임베딩 모델\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ],
   "id": "a44e6baf1e591d86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 리트리버 클래스 로드\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.retrievers import TFIDFRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_community.vectorstores import Chroma"
   ],
   "id": "cb8111ba075f49ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 리트리버 정의\n",
    "\n",
    "## keyword 기반 리트리버\n",
    "bm25 = BM25Retriever.from_documents(docs)\n",
    "tfIdf = TFIDFRetriever.from_documents(docs)\n",
    "\n",
    "## keyword ensemble\n",
    "ensemble_b7_t3 = EnsembleRetriever(retrievers=[bm25, tfIdf], weights=[0.7, 0.3], search_type=\"mmr\")\n",
    "ensemble_b5_t5 = EnsembleRetriever(retrievers=[bm25, tfIdf], weights=[0.5, 0.5], search_type=\"mmr\")\n",
    "ensemble_b3_t7 = EnsembleRetriever(retrievers=[bm25, tfIdf], weights=[0.3, 0.7], search_type=\"mmr\")\n",
    "\n",
    "## embedding 기반 리트리버\n",
    "chroma = Chroma.from_documents(documents=docs, embedding=embeddings).as_retriever()\n",
    "\n",
    "## hybrid 리트리버\n",
    "ensemble_b7_c3 = EnsembleRetriever(retrievers=[bm25, chroma], weights=[0.7, 0.3], search_type=\"mmr\")\n",
    "ensemble_b5_c5 = EnsembleRetriever(retrievers=[bm25, chroma], weights=[0.5, 0.5], search_type=\"mmr\")\n",
    "ensemble_b3_c7 = EnsembleRetriever(retrievers=[bm25, chroma], weights=[0.3, 0.7], search_type=\"mmr\")\n",
    "\n",
    "## 리트리버 리스트\n",
    "retriever_dict = {\n",
    "    'bm25':bm25,\n",
    "    'tfIdf':tfIdf,\n",
    "    'ensemble_b7_t3':ensemble_b7_t3,\n",
    "    'ensemble_b5_t5':ensemble_b5_t5,\n",
    "    'ensemble_b3_t7':ensemble_b3_t7,\n",
    "    'chroma':chroma,\n",
    "    'ensemble_b7_c3':ensemble_b7_c3,\n",
    "    'ensemble_b5_c5':ensemble_b5_c5,\n",
    "    'ensemble_b3_c7':ensemble_b3_c7,\n",
    "}"
   ],
   "id": "c6b167880a8ba3af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# topk 설정\n",
    "top_k = 5"
   ],
   "id": "d998a58bccf685b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# retriver 평가하기\n",
    "import time\n",
    "def eval_retriever(retriever, eval_list):\n",
    "  start = time.time()\n",
    "  results = {\"keyword\":0, \"keyword_kiwi\":0, \"embedding\":0, \"embedding_kiwi\":0, \"hybrid\":0, \"hybrid_kiwi\":0}\n",
    "\n",
    "  for eval in eval_list:\n",
    "    ## 정답 페이지\n",
    "    answer_pages = set(eval[\"answer_pages\"])\n",
    "\n",
    "    ## 정답 여부 확인\n",
    "    is_success = check_invoke_retriever(\n",
    "        retriever=retriever,\n",
    "        question=eval[\"question\"],\n",
    "        answer_pages=answer_pages)\n",
    "\n",
    "    if is_success:\n",
    "      results[eval[\"type\"]] += 1\n",
    "\n",
    "    ## kiwi로 가공한 질문으로 정답 여부 확인\n",
    "    is_success = check_invoke_retriever(\n",
    "        retriever=retriever,\n",
    "        question=kiwi_tokenize(eval[\"question\"]),\n",
    "        answer_pages=answer_pages)\n",
    "\n",
    "    if is_success:\n",
    "      results[f'{eval[\"type\"]}_kiwi'] += 1\n",
    "\n",
    "    exec_time = time.time() - start\n",
    "    # 1회 invoke할때, 평균 실행시간\n",
    "    avg_time = round(exec_time/(len(eval_list)*2), 3)\n",
    "  return avg_time, results\n",
    "\n",
    "# retreiver.invoke후 정답포함여부 리턴\n",
    "def check_invoke_retriever(retriever, question, answer_pages):\n",
    "  return_docs = retriever.invoke(question)[:top_k]\n",
    "  return_pages = set([doc.metadata[\"page\"]+1 for doc in return_docs])\n",
    "  return bool(answer_pages & return_pages)"
   ],
   "id": "48f5235476f4ba36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 리트리버들 invoke\n",
    "results = {}\n",
    "times = {}\n",
    "\n",
    "for name, retriever in retriever_dict.items():\n",
    "  avg_time, result = eval_retriever(retriever, eval_data)\n",
    "  times[name] = avg_time\n",
    "  results[name] = result"
   ],
   "id": "a8a80e331b37c375"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# reranker 관련 변수\n",
    "reranker_name = \"BAAI/bge-reranker-v2-m3\""
   ],
   "id": "f5ae68ce858df450"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# reranker 설정\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "reranker_model = HuggingFaceCrossEncoder(model_name=reranker_name)\n",
    "compressor = CrossEncoderReranker(model=reranker_model, top_n=top_k*2)"
   ],
   "id": "6b7586e0cc8aee8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# rerenker invoke\n",
    "for name, retriever in retriever_dict.items():\n",
    "  reranker = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "  avg_time, result = eval_retriever(reranker, eval_data)\n",
    "  times[f'{name}_rerank'] = avg_time\n",
    "  results[f'{name}_rerank'] = result"
   ],
   "id": "2236736f9390d094"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reranker Custom Class\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "import operator\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_transformers.embeddings_redundant_filter import _DocumentWithState\n",
    "\n",
    "class CustomCrossEncoderReranker(CrossEncoderReranker):\n",
    "    def compress_documents(\n",
    "        self,\n",
    "        documents: Sequence[Document],\n",
    "        query: str,\n",
    "        callbacks: Optional[Callbacks] = None,\n",
    "    ) -> Sequence[Document]:\n",
    "        if not documents:\n",
    "            return []\n",
    "\n",
    "        # 문서 개수가 top_n보다 적은 경우 존재\n",
    "        top_n = min(self.top_n, len(documents))\n",
    "        scores = self.model.score([(query, doc.page_content) for doc in documents])\n",
    "        docs_with_scores = list(zip(documents, scores))\n",
    "\n",
    "        # 정렬후, top_n개 가져옴\n",
    "        results = sorted(docs_with_scores, key=operator.itemgetter(1), reverse=True)[:top_n]\n",
    "\n",
    "        top_n_result = []\n",
    "        for result in results:\n",
    "            doc = result[0]\n",
    "            doc.metadata['score'] = result[1]\n",
    "\n",
    "            if isinstance(doc, _DocumentWithState):\n",
    "                # Wrapper class인 경우, Document로 convert\n",
    "                top_n_result.append(\n",
    "                    Document(\n",
    "                        page_content=doc.page_content,\n",
    "                        metadata=doc.metadata,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                top_n_result.append(doc)\n",
    "\n",
    "        return top_n_result"
   ],
   "id": "f8d368e262bc9a16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# reranker - filter 추가\n",
    "from langchain.retrievers.document_compressors.embeddings_filter import EmbeddingsFilter\n",
    "from langchain.retrievers.document_compressors.base import DocumentCompressorPipeline\n",
    "\n",
    "# 필터 압축 검색기\n",
    "filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.3)\n",
    "compressor_pipeline = DocumentCompressorPipeline(transformers=[filter, compressor])"
   ],
   "id": "a7ace043297beeaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# rerenker(+filter) invoke\n",
    "for name, retriever in retriever_dict.items():\n",
    "  reranker = ContextualCompressionRetriever(base_compressor=compressor_pipeline, base_retriever=retriever)\n",
    "  avg_time, result = eval_retriever(reranker, eval_data)\n",
    "  times[f'{name}_rerank_filter'] = avg_time\n",
    "  results[f'{name}_rerank_filter'] = result"
   ],
   "id": "a498fcfd89014113"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 결과값 -> 그래프 생성\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# nested dict → row 기반 리스트로 변환\n",
    "flat_results = [\n",
    "    {\"retriever\": r_name, \"question_type\": q_type, \"score\": score}\n",
    "    for r_name, q_dict in results.items()\n",
    "    for q_type, score in q_dict.items()\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(flat_results)\n",
    "df.to_csv(f\"{base_path}/rag최적화실험/results/rag_eval_results.csv\", index=False)"
   ],
   "id": "a6abcac92ffef277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(data=df, x=\"retriever\", y=\"score\", hue=\"question_type\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"RAG Retriever Accuracy by Type\")\n",
    "plt.show()"
   ],
   "id": "2deb4e831fbfd9fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "time_results = [\n",
    "    {\"retriever\": r_name, \"avg_time\": avg_time}\n",
    "    for r_name, avg_time in times.items()\n",
    "]\n",
    "\n",
    "time_df = pd.DataFrame(time_results)\n",
    "time_df.to_csv(f\"{base_path}/rag최적화실험/results/rag_eval_times.csv\", index=False)"
   ],
   "id": "9c663b51b213b25a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(data=time_df, x=\"retriever\", y=\"avg_time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"RAG Retriever Average Execution Time by Type\")\n",
    "plt.show()"
   ],
   "id": "10edd714abcb0089"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
